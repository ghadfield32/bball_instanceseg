{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTg0VGYDvGAj0BsFGD5o7+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghadfield32/bball_instanceseg/blob/main/roboflow_r_cnn_auto_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6TiyWHfDYwy",
        "outputId": "9aea349a-89dc-4bf9-94c0-662a6a7baf1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ByteTrack'...\n",
            "remote: Enumerating objects: 2007, done.\u001b[K\n",
            "remote: Total 2007 (delta 0), reused 0 (delta 0), pack-reused 2007\u001b[K\n",
            "Receiving objects: 100% (2007/2007), 79.60 MiB | 16.15 MiB/s, done.\n",
            "Resolving deltas: 100% (1141/1141), done.\n",
            "Updating files: 100% (229/229), done.\n",
            "/content/ByteTrack\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.1.0+cu121)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.8.0.76)\n",
            "Collecting loguru (from -r requirements.txt (line 5))\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.66.1)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.16.0+cu121)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Collecting thop (from -r requirements.txt (line 10))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Collecting ninja (from -r requirements.txt (line 11))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.9.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.15.1)\n",
            "Collecting lap (from -r requirements.txt (line 14))\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting motmetrics (from -r requirements.txt (line 15))\n",
            "  Downloading motmetrics-1.4.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filterpy (from -r requirements.txt (line 16))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (3.9.0)\n",
            "Collecting onnx==1.8.1 (from -r requirements.txt (line 20))\n",
            "  Downloading onnx-1.8.1.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime==1.8.0 (from versions: 1.12.0, 1.12.1, 1.13.1, 1.14.0, 1.14.1, 1.15.0, 1.15.1, 1.16.0, 1.16.1, 1.16.2, 1.16.3)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime==1.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0mNo CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating yolox.egg-info\n",
            "writing yolox.egg-info/PKG-INFO\n",
            "writing dependency_links to yolox.egg-info/dependency_links.txt\n",
            "writing top-level names to yolox.egg-info/top_level.txt\n",
            "writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:502: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "building 'yolox._C' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/content\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc\n",
            "creating build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/cocoeval\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/ByteTrack/yolox/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c /content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.cpp -o build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/ByteTrack/yolox/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c /content/ByteTrack/yolox/layers/csrc/vision.cpp -o build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/vision.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/yolox\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.o build/temp.linux-x86_64-cpython-310/content/ByteTrack/yolox/layers/csrc/vision.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/yolox/_C.cpython-310-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-310/yolox/_C.cpython-310-x86_64-linux-gnu.so -> yolox\n",
            "Creating /usr/local/lib/python3.10/dist-packages/yolox.egg-link (link to .)\n",
            "Adding yolox 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/ByteTrack\n",
            "Processing dependencies for yolox==0.1.0\n",
            "Finished processing dependencies for yolox==0.1.0\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.8)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-tm8mfng1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-tm8mfng1\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (67.7.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=375551 sha256=3ef94e4b7bb4b85634d9adb33d8419ef0aa8ea912336f183fcbf846b647949d2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ewggw6w8/wheels/39/61/b4/480fbddb4d3d6bc34083e7397bc6f5d1381f79acc68e9f3511\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.7\n",
            "    Uninstalling pycocotools-2.0.7:\n",
            "      Successfully uninstalled pycocotools-2.0.7\n",
            "Successfully installed pycocotools-2.0\n",
            "Collecting cython_bbox\n",
            "  Downloading cython_bbox-0.1.5.tar.gz (4.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from cython_bbox) (3.0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cython_bbox) (1.23.5)\n",
            "Building wheels for collected packages: cython_bbox\n",
            "  Building wheel for cython_bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cython_bbox: filename=cython_bbox-0.1.5-cp310-cp310-linux_x86_64.whl size=99039 sha256=8c74f650f626714f82e7746da9e833988de8ab5aa9af462e5b14b6e08676ee37\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/b7/68/bab98b7180cda501101a57fb7d36884218ad45ec60c27cd679\n",
            "Successfully built cython_bbox\n",
            "Installing collected packages: cython_bbox\n",
            "Successfully installed cython_bbox-0.1.5\n",
            "Cloning into 'bball_instanceseg'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd ByteTrack\n",
        "!pip3 install -r requirements.txt\n",
        "!python3 setup.py develop\n",
        "!pip3 install cython\n",
        "!pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!pip3 install cython_bbox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/gautamchitnis/cocoapi.git@cocodataset-master#subdirectory=PythonAPI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8WztQPDGq2I",
        "outputId": "0c0f0f8b-bf02-4faf-ba0d-31e3ac699279"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/gautamchitnis/cocoapi.git@cocodataset-master#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/gautamchitnis/cocoapi.git (to revision cocodataset-master) to /tmp/pip-req-build-tgwexsft\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/gautamchitnis/cocoapi.git /tmp/pip-req-build-tgwexsft\n",
            "  Running command git checkout -b cocodataset-master --track origin/cocodataset-master\n",
            "  Switched to a new branch 'cocodataset-master'\n",
            "  Branch 'cocodataset-master' set up to track remote branch 'cocodataset-master' from 'origin'.\n",
            "  Resolved https://github.com/gautamchitnis/cocoapi.git to commit 20291f19c46a8d11935862bc9e449a1b72ec25ed\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current directory:\", current_directory)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZceSC1C42HZY",
        "outputId": "0cb2176d-9cd3-4261-db4f-86b49b88bad7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Current directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ghadfield32/bball_instanceseg"
      ],
      "metadata": {
        "id": "L0-1P2oUieat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FDnGZCX02hLW",
        "outputId": "783bd791-ee89-4c48-eeb9-3c7b48cd9ee0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.16.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.1.0+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.2.2)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (4.8.0.76)\n",
            "Collecting yt_dlp (from -r requirements.txt (line 19))\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg (from -r requirements.txt (line 20))\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (4.66.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (3.27.9)\n",
            "Collecting onnx (from -r requirements.txt (line 23))\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (5.5.6)\n",
            "Collecting torchinfo (from -r requirements.txt (line 25))\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (2.15.1)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.0)\n",
            "Collecting roboflow (from -r requirements.txt (line 28))\n",
            "  Downloading roboflow-1.1.17-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ultralytics (from -r requirements.txt (line 29))\n",
            "  Downloading ultralytics-8.1.6-py3-none-any.whl (705 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.0/705.0 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 8)) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 8)) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 13)) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 16)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 16)) (3.2.0)\n",
            "Collecting mutagen (from yt_dlp->-r requirements.txt (line 19))\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp->-r requirements.txt (line 19))\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt_dlp->-r requirements.txt (line 19)) (2023.11.17)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt_dlp->-r requirements.txt (line 19)) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt_dlp->-r requirements.txt (line 19))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt_dlp->-r requirements.txt (line 19))\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->-r requirements.txt (line 23)) (3.20.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 24)) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 24)) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 24)) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 24)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 24)) (6.3.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 26)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 26)) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 26)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 26)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 26)) (3.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 26)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 26)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 26)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 26)) (3.0.1)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from pycocotools->-r requirements.txt (line 27)) (3.0.8)\n",
            "Collecting certifi (from yt_dlp->-r requirements.txt (line 19))\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow->-r requirements.txt (line 28))\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 11))\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow->-r requirements.txt (line 28))\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python-headless==4.8.0.74 (from roboflow->-r requirements.txt (line 28))\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from roboflow->-r requirements.txt (line 28))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting supervision (from roboflow->-r requirements.txt (line 28))\n",
            "  Downloading supervision-0.18.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow->-r requirements.txt (line 28)) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow->-r requirements.txt (line 28))\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow->-r requirements.txt (line 28))\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 29)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics->-r requirements.txt (line 29)) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics->-r requirements.txt (line 29))\n",
            "  Using cached thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 26)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 26)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 26)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 26)) (1.3.1)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 24))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 8)) (3.3.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 26)) (2.1.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 24)) (5.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 24)) (23.2.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow->-r requirements.txt (line 28)) (0.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->-r requirements.txt (line 24)) (4.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->-r requirements.txt (line 24)) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 26)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 26)) (3.2.2)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=97bef9d06dba8a9cbc6589b6143e6d57e967280f35db3a176a3b414ddbfacc65\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg, brotli, websockets, torchinfo, python-magic, python-dotenv, pycryptodomex, opencv-python-headless, onnx, mutagen, jedi, idna, cycler, chardet, certifi, yt_dlp, thop, supervision, requests-toolbelt, ultralytics, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed brotli-1.1.0 certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 ffmpeg-1.4 idna-2.10 jedi-0.19.1 mutagen-1.47.0 onnx-1.15.0 opencv-python-headless-4.8.0.74 pycryptodomex-3.20.0 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.17 supervision-0.18.0 thop-0.1.1.post2209072238 torchinfo-1.8.0 ultralytics-8.1.6 websockets-12.0 yt_dlp-2023.12.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cycler",
                  "idna"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required files from torchvision\n",
        "import requests\n",
        "def download_files(urls):\n",
        "    for url in urls:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            with open(url.split(\"/\")[-1], 'wb') as file:\n",
        "                file.write(response.content)\n",
        "        else:\n",
        "            print(f\"Failed to download {url}. Status code: {response.status_code}\")\n",
        "\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\",\n",
        "    \"https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\",\n",
        "    \"https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\",\n",
        "    \"https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\",\n",
        "    \"https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\"\n",
        "]\n",
        "#download_files(urls)"
      ],
      "metadata": {
        "id": "DAtVv3r7TtwJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: this notebook requires torch >= 1.10.0\n",
        "print(torch.__version__)\n",
        "print(\"CUDA available: \", torch.cuda.is_available())\n",
        "\n",
        "\n",
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "B_f0dLL_D46Q",
        "outputId": "d9463bd2-03b1-4e41-da44-339500c8fd9e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "CUDA available:  False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def create_directory(dir_path):\n",
        "    \"\"\"Create a directory if it does not exist.\"\"\"\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "\n",
        "#create going_modular repository\n",
        "create_directory(\"going_modular\")"
      ],
      "metadata": {
        "id": "RlhFu_K5EuhA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/utils.py\n",
        "#!pip install roboflow\n",
        "\n",
        "\n",
        "#from roboflow import Roboflow\n",
        "#rf = Roboflow(api_key=\"htpcxp3XQh7SsgMfjJns\")\n",
        "#project = rf.workspace(\"ai-79z1a\").project(\"basketball_child\")\n",
        "#dataset = project.version(6).download(\"coco-segmentation\")\n",
        "\n",
        "\n",
        "from roboflow import Roboflow\n",
        "import torch\n",
        "import requests\n",
        "import yt_dlp\n",
        "import os\n",
        "\n",
        "def download_videos_from_youtube(video_urls, output_path):\n",
        "    \"\"\"\n",
        "    Downloads videos from YouTube.\n",
        "\n",
        "    Args:\n",
        "    video_urls (list): List of YouTube video URLs.\n",
        "    output_path (str): Directory where videos will be saved.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing lists of successful and failed downloads.\n",
        "    \"\"\"\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'best',\n",
        "        'outtmpl': output_path + '/%(title)s.%(ext)s',\n",
        "        'quiet': True\n",
        "    }\n",
        "\n",
        "    failed_downloads = []\n",
        "    successful_downloads = []\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        for url in video_urls:\n",
        "            try:\n",
        "                ydl.download([url])\n",
        "                print(f\"Successfully downloaded {url}\")\n",
        "                successful_downloads.append(url)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to download {url}: {e}\")\n",
        "                failed_downloads.append(url)\n",
        "\n",
        "    return successful_downloads, failed_downloads\n",
        "\n",
        "\n",
        "def get_device():\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "def get_project(api_key, workspace, project_name, version):\n",
        "    rf = Roboflow(api_key=api_key)\n",
        "    project = rf.workspace(workspace).project(project_name)\n",
        "    dataset = project.version(version).download(\"coco-segmentation\")\n",
        "    return dataset\n",
        "\n",
        "def download_files(urls):\n",
        "    for url in urls:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            with open(url.split(\"/\")[-1], 'wb') as file:\n",
        "                file.write(response.content)\n",
        "        else:\n",
        "            print(f\"Failed to download {url}. Status code: {response.status_code}\")\n",
        "\n",
        "\n",
        "def construct_dataset_paths(project_name, version):\n",
        "    base_path = f\"{project_name}-{version}\"\n",
        "    train_annotation_path = f\"{base_path}/train/_annotations.coco.json\"\n",
        "    valid_annotation_path = f\"{base_path}/valid/_annotations.coco.json\"\n",
        "    test_annotation_path = f\"{base_path}/test/_annotations.coco.json\"\n",
        "\n",
        "    train_root_dir = f\"{base_path}/train\"\n",
        "    valid_root_dir = f\"{base_path}/valid\"\n",
        "    test_root_dir = f\"{base_path}/test\"\n",
        "\n",
        "    return train_annotation_path, valid_annotation_path, test_annotation_path, train_root_dir, valid_root_dir, test_root_dir\n",
        "\n",
        "def create_directory(dir_path):\n",
        "    \"\"\"Create a directory if it does not exist.\"\"\"\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSTP3BeZEqVp",
        "outputId": "93a8101b-c8bb-43c0-88ea-6d202aa4ece6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/coco_dataset.py\n",
        "\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import torch\n",
        "from torchvision.transforms.v2 import functional as F\n",
        "from torchvision import tv_tensors\n",
        "\n",
        "class CustomCocoDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, annotation_path, root_dir, transforms=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        with open(annotation_path) as f:\n",
        "            self.annotations = json.load(f)\n",
        "\n",
        "        # Filter out images without annotations\n",
        "        annotated_images = []\n",
        "        for img in self.annotations['images']:\n",
        "            image_id = img['id']\n",
        "            anns = [ann for ann in self.annotations['annotations'] if ann['image_id'] == image_id]\n",
        "            if len(anns) > 0:\n",
        "                annotated_images.append(img)\n",
        "\n",
        "        self.image_ids = [img['id'] for img in annotated_images]\n",
        "\n",
        "        # Update the self.annotations['images'] to include only annotated images\n",
        "        self.annotations['images'] = annotated_images\n",
        "\n",
        "        #print(\"Number of images:\", len(self.annotations['images']))\n",
        "        #print(\"Sample image entry:\", self.annotations['images'][0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations['images'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_info = self.annotations['images'][idx]\n",
        "        image_id = img_info['id']\n",
        "\n",
        "        img_path = os.path.join(self.root_dir, img_info['file_name'])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img_tensor = F.to_tensor(img)\n",
        "        #print(\"Image size (PIL):\", img.size)\n",
        "        #print(\"Image shape (tensor):\", img_tensor.shape)\n",
        "\n",
        "        anns = [ann for ann in self.annotations['annotations'] if ann['image_id'] == image_id]\n",
        "        #print(\"Number of annotations for this image:\", len(anns))\n",
        "\n",
        "        boxes = [ann['bbox'] for ann in anns]  # bbox format: [x_min, y_min, width, height]\n",
        "        # Convert from XYWH to XYXY format\n",
        "        boxes = [[box[0], box[1], box[0] + box[2], box[1] + box[3]] for box in boxes]\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = [ann['category_id'] for ann in anns]\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        #print(\"Boxes shape:\", boxes.shape)\n",
        "        #print(\"Labels:\", labels)\n",
        "        # Debug print\n",
        "        #print(f\"Boxes shape for image {idx}: {boxes.shape}\")\n",
        "\n",
        "        masks = []\n",
        "        for ann in anns:\n",
        "            if 'segmentation' in ann and isinstance(ann['segmentation'], list):\n",
        "                for seg in ann['segmentation']:\n",
        "                    mask_img = Image.new('L', (img_info['width'], img_info['height']), 0)\n",
        "                    ImageDraw.Draw(mask_img).polygon(seg, outline=1, fill=1)\n",
        "                    mask = np.array(mask_img)\n",
        "                    masks.append(mask)\n",
        "        masks = torch.as_tensor(np.array(masks), dtype=torch.uint8) if masks else torch.zeros((0, img_info['height'], img_info['width']), dtype=torch.uint8)\n",
        "        #print(\"Masks shape:\", masks.shape)\n",
        "\n",
        "        areas = [ann['area'] for ann in anns]\n",
        "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "        iscrowd = [ann['iscrowd'] for ann in anns]\n",
        "        iscrowd = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
        "\n",
        "        # Convert masks to Mask format\n",
        "        masks = tv_tensors.Mask(masks)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id  # Changed to integer\n",
        "        target[\"area\"] = areas\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        #print(\"Target:\", target)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img_tensor, target = self.transforms(img_tensor, target)\n",
        "\n",
        "        return img_tensor, target\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rKX4lCNEsBH",
        "outputId": "d8b6593c-34cc-4e54-8d76-80edbd44afdb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/coco_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/visualization_utils.py\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as F  # Add this import\n",
        "\n",
        "# New function to visualize transformations\n",
        "def visualize_transformation(dataset, idx):\n",
        "    img, target = dataset[idx]\n",
        "    transformed_img, transformed_target = dataset.transforms(img, target)\n",
        "    original_img = F.to_pil_image(img)\n",
        "    transformed_img = F.to_pil_image(transformed_img)\n",
        "\n",
        "    plt.figure(figsize=(24, 6))\n",
        "    # Original Image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original_img)\n",
        "    for box in target[\"boxes\"]:\n",
        "        x_min, y_min, x_max, y_max = box.tolist()\n",
        "        rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        plt.gca().add_patch(rect)\n",
        "        #print(x_min, y_min, x_max, y_max)\n",
        "    plt.title(f\"Original Image - ID: {idx}\")\n",
        "\n",
        "    # Transformed Image\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(transformed_img)\n",
        "    for box in transformed_target[\"boxes\"]:\n",
        "        x_min, y_min, x_max, y_max = box.tolist()\n",
        "        rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor='b', facecolor='none')\n",
        "        plt.gca().add_patch(rect)\n",
        "        #print(x_min, y_min, x_max, y_max)\n",
        "    plt.title(f\"Transformed Image - ID: {idx}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def visualize_bbox(dataset, idx):\n",
        "    img, target = dataset[idx]\n",
        "    original_img = F.to_pil_image(img)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(original_img)\n",
        "\n",
        "    for box in target[\"boxes\"]:  # Access the boxes directly\n",
        "        x_min, y_min, x_max, y_max = box.tolist()\n",
        "        # Debug print\n",
        "        print(f\"Visualizing BBox - xmin: {x_min}, ymin: {y_min}, xmax: {x_max}, ymax: {y_max}\")\n",
        "        rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "    plt.title(f\"Image with Bounding Boxes - ID: {idx}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijXbdNRJFA_J",
        "outputId": "8b8fe845-e10f-48d5-b457-21e0f42518f6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/visualization_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/model_utils.py\n",
        "import json\n",
        "import torchvision\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "\n",
        "def load_classes_from_json(file_path):\n",
        "    \"\"\"\n",
        "    Loads the class names and their corresponding IDs from a COCO format JSON file.\n",
        "\n",
        "    Args:\n",
        "    file_path (str): Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are class IDs and values are class names.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Extracting classes and their IDs\n",
        "    classes = {category['id']: category['name'] for category in data['categories']}\n",
        "    return classes\n",
        "\n",
        "# Usage example:\n",
        "#classes = load_classes_from_json('basketball_child-6/test/_annotations.coco.json')\n",
        "#print(classes)\n",
        "\n",
        "# model_utils.py\n",
        "def get_model_instance_segmentation(num_classes, hidden_layer=256):\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXwBfXJlFGrB",
        "outputId": "078383a0-5ab1-458d-90e0-cda6e16a296f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/model_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/transforms.py\n",
        "import torch  # Add this import statement\n",
        "from torchvision.transforms import v2 as T\n",
        "from torchvision.transforms import Compose, RandomHorizontalFlip, ToTensor, ConvertImageDtype\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    #if train:\n",
        "    #    transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
        "    transforms.append(T.ToPureTensor())\n",
        "    return T.Compose(transforms)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vZGpgpyFIT4",
        "outputId": "b0738439-ba19-497c-be14-da33955b3865"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/transforms.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/engine.py\n",
        "# train.py\n",
        "import torch\n",
        "import torchvision\n",
        "from engine import train_one_epoch, evaluate\n",
        "from coco_utils import get_coco_api_from_dataset\n",
        "from coco_eval import CocoEvaluator\n",
        "\n",
        "def train_model(model, data_loader, data_loader_valid, device, num_epochs,\n",
        "                lr=0.005, momentum=0.9, weight_decay=0.0005, step_size=3, gamma=0.1):\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "        lr_scheduler.step()\n",
        "        evaluate(model, data_loader_valid, device=device)\n",
        "\n",
        "    torch.save(model.state_dict(), 'models/model_weights.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixX3QBTfGCTw",
        "outputId": "aafa8c28-9209-4942-c535-4974f0b6f096"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/process_video_check.py\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.transforms import v2 as T\n",
        "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
        "\n",
        "def intersects(box1, box2):\n",
        "    x1_min, y1_min, x1_max, y1_max = box1.tolist()\n",
        "    x2_min, y2_min, x2_max, y2_max = box2.tolist()\n",
        "    return (x1_min < x2_max and x1_max > x2_min and y1_min < y2_max and y1_max > y2_min)\n",
        "\n",
        "def process_video_check(video_path, model, device, classes, classes_to_track, threshold=0.5):\n",
        "    model.eval()\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        return\n",
        "\n",
        "    score = 0  # Initialize the score counter\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_tensor = T.ToTensor()(frame).unsqueeze_(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model(frame_tensor)[0]\n",
        "\n",
        "        pred_scores = prediction['scores']\n",
        "        pred_boxes = prediction['boxes']\n",
        "        pred_labels = prediction['labels']\n",
        "        pred_masks = prediction['masks']\n",
        "\n",
        "        keep = pred_scores > threshold\n",
        "        pred_boxes = pred_boxes[keep]\n",
        "        pred_labels = pred_labels[keep]\n",
        "        pred_masks = pred_masks[keep]\n",
        "\n",
        "        if not keep.any():\n",
        "            continue  # Skip this frame if no detections are kept\n",
        "\n",
        "        # Convert numeric labels to class names\n",
        "        pred_class_names = [classes[label.item()] for label in pred_labels]\n",
        "\n",
        "        # Iterate through each pair of classes to track\n",
        "        for class_pair in classes_to_track:\n",
        "            class1_boxes = pred_boxes[[name == class_pair[0] for name in pred_class_names]]\n",
        "            class2_boxes = pred_boxes[[name == class_pair[1] for name in pred_class_names]]\n",
        "\n",
        "            # Check for intersections and update score\n",
        "            for box1 in class1_boxes:\n",
        "                for box2 in class2_boxes:\n",
        "                    if intersects(box1, box2):\n",
        "                        score += 1\n",
        "                        print(f\"Intersection detected between {class_pair[0]} and {class_pair[1]}, Score:\", score)\n",
        "\n",
        "        # Frame Tensor Conversion for Drawing\n",
        "        frame_tensor = (255.0 * (frame_tensor - frame_tensor.min()) / (frame_tensor.max() - frame_tensor.min())).to(torch.uint8)\n",
        "        frame_tensor = frame_tensor.squeeze().to(torch.uint8)\n",
        "\n",
        "        # Draw bounding boxes and segmentation masks\n",
        "        output_image = draw_bounding_boxes(frame_tensor, pred_boxes, labels=pred_class_names, colors=\"red\")\n",
        "        output_image = draw_segmentation_masks(output_image, (pred_masks > 0.7).squeeze(1), alpha=0.5, colors=\"blue\")\n",
        "\n",
        "        # Convert output image for displaying\n",
        "        output_image = output_image.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
        "        output_image = np.clip(output_image, 0, 255)  # Ensure values are within 0-255\n",
        "\n",
        "        # Draw score text\n",
        "        cv2.putText(output_image, f'Score: {score}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "        cv2.imshow('Frame', output_image)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Example usage\n",
        "# process_video_check(video_path, model, device, classes, [('ball', 'rim')], threshold=0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tQeRmH_GD-Q",
        "outputId": "183a6594-6255-4e91-e4ea-d6d9de1b2396"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/process_video_check.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import argparse\n",
        "import os\n",
        "from going_modular.utils import (get_device, create_directory, get_project,\n",
        "                                 download_files, construct_dataset_paths,\n",
        "                                 download_videos_from_youtube)\n",
        "from going_modular.coco_dataset import CustomCocoDataset\n",
        "from going_modular.model_utils import (get_model_instance_segmentation,\n",
        "                                       load_classes_from_json)\n",
        "from going_modular.engine import train_model\n",
        "from going_modular.transforms import get_transform\n",
        "from going_modular.process_video_check import process_video_check\n",
        "import utils\n",
        "import torch\n",
        "from torch import nn\n",
        "from pathlib import Path\n",
        "\n",
        "# Note: this notebook requires torch >= 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "\n",
        "def main(args):\n",
        "    # Create directories for data and models\n",
        "    data_path = Path(args.data_path)\n",
        "    model_path = Path(args.model_path)\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "    model_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Get the project dataset\n",
        "    dataset = get_project(args.api_key, args.workspace, args.project_name, args.version)\n",
        "\n",
        "    # Load classes from json\n",
        "    classes = load_classes_from_json(f'{args.project_folder_name}-{args.version}/test/_annotations.coco.json')\n",
        "    print(classes)\n",
        "\n",
        "    # Set the number of classes\n",
        "    num_classes = len(classes) + 1\n",
        "\n",
        "    # Initialize device\n",
        "    device = get_device()\n",
        "\n",
        "    # Construct dataset paths\n",
        "    train_annotation_path, valid_annotation_path, test_annotation_path, train_image_dir, valid_image_dir, test_image_dir = construct_dataset_paths(args.project_folder_name, args.version)\n",
        "\n",
        "    # Create datasets with transforms\n",
        "    train_dataset = CustomCocoDataset(train_annotation_path, train_image_dir, transforms=get_transform(train=True))\n",
        "    valid_dataset = CustomCocoDataset(valid_annotation_path, valid_image_dir, transforms=get_transform(train=False))\n",
        "    test_dataset = CustomCocoDataset(test_annotation_path, test_image_dir)\n",
        "\n",
        "    # Load model\n",
        "    model = get_model_instance_segmentation(num_classes,\n",
        "                                            hidden_layer=args.hidden_layer)\n",
        "    model.to(device)\n",
        "\n",
        "    # Data Loaders\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0, collate_fn=utils.collate_fn)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=utils.collate_fn)\n",
        "    test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=utils.collate_fn)\n",
        "\n",
        "    # Train the model\n",
        "    train_model(model, train_data_loader, valid_data_loader, device, args.num_epochs, lr=args.lr)\n",
        "\n",
        "    # Save model after training\n",
        "    model_file_path = model_path / 'model_weights.pth'\n",
        "    try:\n",
        "        torch.save(model.state_dict(), str(model_file_path))\n",
        "        print(\"Model saved at:\", model_file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\")\n",
        "\n",
        "    # Download and process video\n",
        "    try:\n",
        "        successful_downloads, failed_downloads = download_videos_from_youtube([args.video_url], args.data_path)\n",
        "        print(f\"Successfully downloaded {len(successful_downloads)} videos.\")\n",
        "        print(f\"Failed to download {len(failed_downloads)} videos.\")\n",
        "\n",
        "        if successful_downloads:\n",
        "            # Construct video path\n",
        "            video_filename = args.video_name\n",
        "            if not video_filename.endswith('.mp4'):\n",
        "                video_filename += '.mp4'\n",
        "            video_path = data_path / video_filename\n",
        "            print(f\"Video path: {video_path}\")\n",
        "\n",
        "            # Load model state for video processing\n",
        "            model.load_state_dict(torch.load(str(model_file_path), map_location=device))\n",
        "            model.to(device)\n",
        "\n",
        "            # Process video\n",
        "            process_video_check(video_path, model, device, classes, [('Basketball', 'Hoop')], threshold=args.threshold)\n",
        "        else:\n",
        "            print(\"No videos were downloaded.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in video downloading or processing: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Train a model for object detection\")\n",
        "    # Define default values\n",
        "    default_api_key = \"your_roboflow_api_key\"\n",
        "    default_workspace = \"your_roboflow_workspace\"\n",
        "    default_project_name = \"your_roboflow_project\"\n",
        "    default_project_folder_name = \"your_roboflow_project_folder_name\"\n",
        "    default_version = 1\n",
        "    default_hidden_layer = 256\n",
        "    default_lr = 0.005\n",
        "    default_num_epochs = 10\n",
        "    default_video_url = \"https://www.youtube.com/watch?v=example_video_id\"\n",
        "    default_video_name = \"your_youtube_video_name\"\n",
        "    default_confidence_threshold = 0.6\n",
        "    default_display_video = True\n",
        "    default_data_path = 'results/data'\n",
        "    default_model_path = 'results/models'\n",
        "\n",
        "    # Setup argparse with defaults\n",
        "    parser.add_argument('--api_key', type=str, default=default_api_key, help='API key for Roboflow')\n",
        "    parser.add_argument('--workspace', type=str, default=default_workspace, help='Workspace name in Roboflow')\n",
        "    parser.add_argument('--project_name', type=str, default=default_project_name, help='Project name in Roboflow')\n",
        "    parser.add_argument('--project_folder_name', type=str, default=default_project_folder_name, help='Project folder name in Roboflow')\n",
        "    parser.add_argument('--version', type=int, default=default_version, help='Version of the dataset in Roboflow')\n",
        "    parser.add_argument('--hidden_layer', type=int, default=default_hidden_layer, help='Hidden layer size for the MaskRCNN predictor')\n",
        "    parser.add_argument('--lr', type=float, default=default_lr, help='Learning rate')\n",
        "    parser.add_argument('--num_epochs', type=int, default=default_num_epochs, help='Number of epochs to train the model')\n",
        "    parser.add_argument('--video_url', type=str, default=default_video_url, help='URL of the video to process')\n",
        "    parser.add_argument('--video_name', type=str, default=default_video_name, help='Name of the video file (with extension) to process')\n",
        "    parser.add_argument('--threshold', type=float, default=default_confidence_threshold, help='Detection threshold for process_video')\n",
        "    parser.add_argument('--display_video', type=bool, default=default_display_video, help='Whether to display the video during processing')\n",
        "    parser.add_argument('--data_path', type=str, default=default_data_path, help='Path to save downloaded data')\n",
        "    parser.add_argument('--model_path', type=str, default=default_model_path, help='Path to save model weights')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7LvD4NxGFmp",
        "outputId": "cd758fcd-55c2-4b7b-c6b7-ebb3ca0e94c7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example usage\n",
        "!python train.py --api_key htpcxp3XQh7SsgMfjJns \\\n",
        "                --workspace basketball-formations \\\n",
        "                --project_name basketball-and-hoop-7xk0h \\\n",
        "                --project_folder_name basketball-and-hoop \\\n",
        "                --version 10 \\\n",
        "                --hidden_layer 256 \\\n",
        "                --lr 0.005 \\\n",
        "                --num_epochs 1 \\\n",
        "                --threshold 0.6 \\\n",
        "                --video_url \"https://www.youtube.com/watch?v=y8i6fsAXDZE\" \\\n",
        "                --video_name \"The Best NBA 3 Point Contest Performances\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X87HNmVqGJag",
        "outputId": "54fffff3-1f6c-42bb-ebce-6b0f167ef2ad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in basketball-and-hoop-10 to coco-segmentation:: 100% 128180/128180 [00:06<00:00, 20277.28it/s]\n",
            "\n",
            "Extracting Dataset Version Zip to basketball-and-hoop-10 in coco-segmentation:: 100% 1877/1877 [00:01<00:00, 1232.14it/s]\n",
            "{0: 'Basketball-and-Hoop', 1: 'Basketball', 2: 'Hoop', 3: 'Player', 4: 'backboard'}\n",
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
            "100% 170M/170M [00:06<00:00, 28.0MB/s]\n",
            "The function `to_tensor(...)` is deprecated and will be removed in a future release. Instead, please use `to_image(...)` followed by `to_dtype(..., dtype=torch.float32, scale=True)`.\n",
            "Epoch: [0]  [  0/700]  eta: 8:31:25  lr: 0.000012  loss: 3.5825 (3.5825)  loss_classifier: 1.8518 (1.8518)  loss_box_reg: 0.3083 (0.3083)  loss_mask: 1.0844 (1.0844)  loss_objectness: 0.2746 (0.2746)  loss_rpn_box_reg: 0.0634 (0.0634)  time: 43.8364  data: 0.0762\n",
            "Epoch: [0]  [ 10/700]  eta: 8:33:08  lr: 0.000084  loss: 3.5825 (3.6007)  loss_classifier: 1.7056 (1.7014)  loss_box_reg: 0.4224 (0.4189)  loss_mask: 1.0936 (1.2017)  loss_objectness: 0.1574 (0.1881)  loss_rpn_box_reg: 0.0634 (0.0905)  time: 44.6215  data: 0.0328\n",
            "Epoch: [0]  [ 20/700]  eta: 8:32:02  lr: 0.000155  loss: 3.1028 (3.2333)  loss_classifier: 1.4512 (1.3868)  loss_box_reg: 0.4260 (0.4476)  loss_mask: 1.0795 (1.0949)  loss_objectness: 0.1248 (0.1882)  loss_rpn_box_reg: 0.0902 (0.1159)  time: 45.2471  data: 0.0296\n",
            "Epoch: [0]  [ 30/700]  eta: 8:28:00  lr: 0.000227  loss: 2.1624 (2.7643)  loss_classifier: 0.6048 (1.0996)  loss_box_reg: 0.4398 (0.4384)  loss_mask: 0.7428 (0.9542)  loss_objectness: 0.1131 (0.1629)  loss_rpn_box_reg: 0.0983 (0.1091)  time: 45.9723  data: 0.0318\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train.py\", line 134, in <module>\n",
            "    main(args)\n",
            "  File \"/content/train.py\", line 63, in main\n",
            "    train_model(model, train_data_loader, valid_data_loader, device, args.num_epochs, lr=args.lr)\n",
            "  File \"/content/going_modular/engine.py\", line 15, in train_model\n",
            "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
            "  File \"/content/engine.py\", line 51, in train_one_epoch\n",
            "    losses.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 492, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 251, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nEq1gNIrV3qQ"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}